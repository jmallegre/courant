{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3955e719-e91b-41f6-ba17-7c9fbbb2af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a7cade-71a6-45cf-a033-0feca0d2f1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeanm\\AppData\\Local\\Temp\\ipykernel_37292\\2335758478.py:2: DtypeWarning: Columns (3,8,10,12,28,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv('data_2022.csv')\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv('C:/Users/dell/Desktop/Formation Machine Learning engineer/Projet fil rouge/data_cleaned.csv')\n",
    "df=pd.read_csv('data_2022.csv')\n",
    "#df = df.drop('Unnamed: 0', axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba800f05-ab88-4708-8361-f6070fd7ec3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ce4f587-92fc-416c-8a91-38a187811b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Country', 'VFN', 'Mp', 'Mh', 'Man', 'MMS', 'Tan', 'T', 'Va',\n",
       "       'Ve', 'Mk', 'Cn', 'Ct', 'Cr', 'r', 'm (kg)', 'Mt', 'Enedc (g/km)',\n",
       "       'Ewltp (g/km)', 'W (mm)', 'At1 (mm)', 'At2 (mm)', 'Ft', 'Fm',\n",
       "       'ec (cm3)', 'ep (KW)', 'z (Wh/km)', 'IT', 'Ernedc (g/km)',\n",
       "       'Erwltp (g/km)', 'De', 'Vf', 'Status', 'year', 'Date of registration',\n",
       "       'Fuel consumption ', 'Electric range (km)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72d3f16e-f1d6-47a5-bd91-d1f600f18569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les noms des colonnes catégorielles\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Utilisation de la fonction get_dummies de Pandas pour la dichotomisation\n",
    "#fuel_dummies = pd.get_dummies(df['Fuel_type'], prefix='Fuel', drop_first=True)\n",
    "fuel_dummies = pd.get_dummies(df['Ft'], prefix='Fuel', drop_first=True)\n",
    "df = pd.concat([df, fuel_dummies], axis=1)\n",
    "#\n",
    "#country_dummies = pd.get_dummies(df['Pays'], prefix='Country', drop_first=True)\n",
    "country_dummies = pd.get_dummies(df['Country'], prefix='Country', drop_first=True)\n",
    "df = pd.concat([df, country_dummies], axis=1)\n",
    "\n",
    "manufacturer_dummies = pd.get_dummies(df['Mp'], prefix='Manufacturer', drop_first=True)\n",
    "df = pd.concat([df, manufacturer_dummies], axis=1)\n",
    "#supprimer les variables 'pays', 'fabriquant' et 'fuel_type' :\n",
    "#df = df.drop(['Fuel_type','Pays', 'Fabricant'], axis=1)  \n",
    "df = df.drop(['Ft','Country', 'Mp'], axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6a2d700-fbb2-4f25-a424-73718b17bbed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'VFN', 'Mh', 'Man', 'MMS', 'Tan', 'T', 'Va', 'Ve', 'Mk',\n",
       "       ...\n",
       "       'Country_SK', 'Manufacturer_FORD', 'Manufacturer_HYUNDAI MOTOR EUROPE',\n",
       "       'Manufacturer_KIA', 'Manufacturer_MAZDA-SUBARU-SUZUKI-TOYOTA',\n",
       "       'Manufacturer_MERCEDES-BENZ', 'Manufacturer_RENAULT-NISSAN-MITSUBISHI',\n",
       "       'Manufacturer_STELLANTIS', 'Manufacturer_TESLA-HONDA-JLR',\n",
       "       'Manufacturer_VOLKSWAGEN'],\n",
       "      dtype='object', length=127)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "629e3fe9-a70c-44c3-96c6-6e94381638c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'IP-07A1A1E024A_000-VF1-1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Charger votre DataFrame (à adapter selon votre source de données)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# df = pd.read_csv('votre_dataset.csv')\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Calculer la matrice de corrélation\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m correlation_matrix \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcorr()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Créer la heatmap\u001b[39;00m\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10704\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  10702\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  10703\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 10704\u001b[0m mat \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto_numpy(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m, na_value\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m  10706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  10707\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:1889\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1888\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1889\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mas_array(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, na_value\u001b[38;5;241m=\u001b[39mna_value)\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1891\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1656\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1654\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1656\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interleave(dtype\u001b[38;5;241m=\u001b[39mdtype, na_value\u001b[38;5;241m=\u001b[39mna_value)\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1715\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1713\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1714\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1715\u001b[0m     result[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1716\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'IP-07A1A1E024A_000-VF1-1'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Charger votre DataFrame (à adapter selon votre source de données)\n",
    "# df = pd.read_csv('votre_dataset.csv')\n",
    "\n",
    "# Calculer la matrice de corrélation\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Créer la heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Heatmap des corrélations')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa38068f-68da-4ef3-8d04-fa6846ccf39d",
   "metadata": {},
   "source": [
    "### <font color='blue'> scinder le data en deux : </font>\n",
    "Nous allons decouper le data en deux parties : voitures hybrides et voiture thermiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d8eba-f94d-47f5-89f5-30ad78bb58f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybride = df[df['Consommation_électrique']!=0.0]\n",
    "df_thermique = df[df['Consommation_électrique']==0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb4deb-5813-4288-aac3-bc83f1f9c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybride.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fcbc9c-bbc2-45ab-8c50-800cddce708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thermique = df_thermique.drop(columns=['Autonomie_électrique','Consommation_électrique','Fuel_petrol/electric'])\n",
    "df_thermique.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d212817-9e7c-4513-8d61-6e324460f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybride = df_hybride.drop(columns=['Fuel_lpg', 'Fuel_petrol', 'Fuel_petrol/electric'])\n",
    "df_hybride.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861afc9-48c7-4332-a8c7-25f0fd86bb1e",
   "metadata": {},
   "source": [
    "### <font color='blue'> Supprimer Consommation electrique et Fuel_petrol/electric : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1408b4e8-9119-4859-8c5d-4cc1cb57a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybride = df_hybride.drop('Consommation_électrique', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461757e5-587d-462f-a105-37109d6a77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hybride.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceda2e2b-03aa-4341-aca7-de1709b84a9f",
   "metadata": {},
   "source": [
    "### <font color='blue'> Analyse data voitures thermiques : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def64b4-db51-4ea0-8388-e3ca8cff61e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Tracer un histogramme\n",
    "#sns.histplot(df_non_hybride['Emission_co2_(g/km)'], kde=True, bins=50, edgecolor='black')\n",
    "sns.histplot(df_thermique['Emission_co2_(g/km)'], kde=True, bins=50, edgecolor='black', color='blue', line_kws={'color': 'red', 'linewidth': 2})\n",
    "\n",
    "\n",
    "# Calculer la moyenne et la médiane\n",
    "mean_value = df_thermique['Emission_co2_(g/km)'].mean()\n",
    "median_value = df_thermique['Emission_co2_(g/km)'].median()\n",
    "\n",
    "# Tracer des lignes verticales pour représenter la moyenne et la médiane\n",
    "plt.axvline(mean_value, color='red', linewidth=1, label='Moyenne de distribution')\n",
    "plt.axvline(median_value, color='red', linestyle='dashed', linewidth=1, label='Médiane de distribution')\n",
    "\n",
    "# Ajouter une légende\n",
    "plt.legend()\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b456400d-26c4-4f2e-8665-2e1619fa5dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_thermique['Emission_co2_(g/km)']\n",
    "X = df_thermique.drop('Emission_co2_(g/km)', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10efce06-359d-447e-a8aa-08270564830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardiser les données\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a913879-4b72-4ddf-b894-c0108c848fd2",
   "metadata": {},
   "source": [
    "### <font color='blue'> sans validation croisée : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc66fc7-dcaf-4534-bbc5-93bf919dd16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "# Création et entraînement du modèle de régression linéaire\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédiction des valeurs cibles pour les ensembles d'entraînement et de test\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calcul des métriques pour l'entraînement\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "# Calcul des métriques pour le test\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print(\"Régression Linéaire sans validation croisée\")\n",
    "print(f\"R² pour l'entraînement : {r2_train}\")\n",
    "print(f\"R² pour le test : {r2_test}\")\n",
    "print(f\"MAE pour l'entraînement : {mae_train}\")\n",
    "print(f\"MAE pour le test : {mae_test}\")\n",
    "print(f\"RMSE pour l'entraînement : {rmse_train}\")\n",
    "print(f\"RMSE pour le test : {rmse_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b443d4-a313-408e-a858-d7e7c363d9a3",
   "metadata": {},
   "source": [
    "### <font color='blue'> avec validation croisée : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a13b20-aaf2-4157-9cce-18135a30b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "# Validation croisée\n",
    "cv_results = cross_validate(model, X_train_scaled, y_train, cv=10,\n",
    "                            scoring=('r2', 'neg_mean_absolute_error', 'neg_root_mean_squared_error'),\n",
    "                            return_train_score=True)\n",
    "\n",
    "# Moyennes des scores R², MAE et RMSE pour l'entraînement et le test\n",
    "mean_r2_train = np.mean(cv_results['train_r2'])\n",
    "mean_r2_test = np.mean(cv_results['test_r2'])\n",
    "mean_mae_train = -np.mean(cv_results['train_neg_mean_absolute_error'])\n",
    "mean_mae_test = -np.mean(cv_results['test_neg_mean_absolute_error'])\n",
    "mean_rmse_train = -np.mean(cv_results['train_neg_root_mean_squared_error'])\n",
    "mean_rmse_test = -np.mean(cv_results['test_neg_root_mean_squared_error'])\n",
    "\n",
    "print(\"Régression Linéaire avec validation croisée\")\n",
    "print(f\"R² moyen pour l'entraînement : {mean_r2_train}\")\n",
    "print(f\"R² moyen pour le test : {mean_r2_test}\")\n",
    "print(f\"MAE moyen pour l'entraînement : {mean_mae_train}\")\n",
    "print(f\"MAE moyen pour le test : {mean_mae_test}\")\n",
    "print(f\"RMSE moyen pour l'entraînement : {mean_rmse_train}\")\n",
    "print(f\"RMSE moyen pour le test : {mean_rmse_test}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b1d729-73a1-49a0-ae1d-02a89d7d2d76",
   "metadata": {},
   "source": [
    "### <font color='blue'> analyse des residus : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a545d8-1fe0-4084-8cb3-fdbb125a31f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer les résidus\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "# Visualiser les résidus\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Distribution des résidus')\n",
    "plt.xlabel('Résidus')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.show()\n",
    "# Enregistrer l'image\n",
    "plt.savefig('distribution des lr thermiques.png', bbox_inches='tight')\n",
    "\n",
    "# Vérifier l'homoscédasticité\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test_pred, y=residuals)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.title('Résidus par rapport aux valeurs prédites')\n",
    "plt.xlabel('Valeurs prédites')\n",
    "plt.ylabel('Résidus')\n",
    "plt.show()\n",
    "\n",
    "# Enregistrer l'image\n",
    "plt.savefig('residus par rapport aux valeurs predites lr thermiques.png', bbox_inches='tight')\n",
    "\n",
    "# Vérifier l'indépendance des résidus\n",
    "# (Visualisation des résidus par rapport à l'ordre des observations ou à une autre variable)\n",
    "# Utilisation de tests statistiques pour la normalité des résidus, l'homoscédasticité, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a213d8f-52f3-4929-8431-0ad1038e0688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculer les résidus normalisés\n",
    "residuals_standardized = (residuals - residuals.mean()) / residuals.std()\n",
    "\n",
    "# Q-Q plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "stats.probplot(residuals_standardized, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q Plot des Résidus\")\n",
    "plt.xlabel(\"Quantiles théoriques (distribution normale)\")\n",
    "plt.ylabel(\"Quantiles observés\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae46768-cf1b-46b6-b8d3-006ec41ee131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculer la moyenne et l'écart type des résidus\n",
    "residuals_mean = np.mean(residuals)\n",
    "residuals_std = np.std(residuals)\n",
    "\n",
    "# Créer le graphique des résidus en fonction des valeurs prédites avec moyenne et écart type\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_train_pred, residuals, alpha=0.5)\n",
    "plt.title(\"Graphique des résidus en fonction des valeurs prédites\")\n",
    "plt.xlabel(\"Valeurs prédites\")\n",
    "plt.ylabel(\"Résidus\")\n",
    "plt.axhline(y=0, color='crimson', linestyle='--')  # Ajouter une ligne horizontale à y=0 pour référence\n",
    "plt.axhline(y=residuals_mean, color='crimson', linestyle='-',linewidth=2, label='Moyenne des résidus')  # Ajouter la moyenne des résidus\n",
    "plt.axhline(y=residuals_mean + 2*residuals_std, color='crimson', linestyle='--', label='±2 σ')  # Ajouter les barres d'écart type\n",
    "plt.axhline(y=residuals_mean - 2*residuals_std, color='crimson', linestyle='--')\n",
    "plt.axhline(y=residuals_mean + 3*residuals_std, color='crimson', linestyle='-', label='±3 σ')  # Ajouter les barres d'écart type\n",
    "plt.axhline(y=residuals_mean - 3*residuals_std, color='crimson', linestyle='-')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ae8a05-865a-4ab6-adc9-e59abea8c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Créer le nuage de points entre les valeurs prédites et les valeurs réelles avec une ligne de corrélation\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test_pred, y_test, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)  # Ajouter une ligne de corrélation parfaite\n",
    "plt.title(\"Nuage de points entre les valeurs prédites et les valeurs réelles (test)\")\n",
    "plt.xlabel(\"Valeurs prédites\")\n",
    "plt.ylabel(\"Valeurs réelles\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c59fce-b66f-4fdd-b20c-61d9e630c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Définir le style de Seaborn sur darkgrid\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# Créer la boîte à moustaches des résidus avec Seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=residuals, orient='h', color='cornflowerblue')\n",
    "plt.title(\"Boîte à moustaches des résidus\")\n",
    "plt.xlabel(\"Résidus\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06790623-63e7-48a9-ad61-c8542900794b",
   "metadata": {},
   "source": [
    "#### <font color='pink'> Elasticnet ridge et lasso : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a21182c-a600-4310-900e-d5e7982af7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialiser les modèles\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "ridge = Ridge(alpha=0.1)\n",
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "# Entraîner les modèles\n",
    "elastic_net.fit(X_train_scaled, y_train)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédire les valeurs cibles pour les ensembles d'entraînement et de test\n",
    "y_train_pred_elastic_net = elastic_net.predict(X_train_scaled)\n",
    "y_test_pred_elastic_net = elastic_net.predict(X_test_scaled)\n",
    "\n",
    "y_train_pred_ridge = ridge.predict(X_train_scaled)\n",
    "y_test_pred_ridge = ridge.predict(X_test_scaled)\n",
    "\n",
    "y_train_pred_lasso = lasso.predict(X_train_scaled)\n",
    "y_test_pred_lasso = lasso.predict(X_test_scaled)\n",
    "\n",
    "# Calculer les scores R² pour l'entraînement et le test\n",
    "r2_train_elastic_net = r2_score(y_train, y_train_pred_elastic_net)\n",
    "r2_test_elastic_net = r2_score(y_test, y_test_pred_elastic_net)\n",
    "\n",
    "r2_train_ridge = r2_score(y_train, y_train_pred_ridge)\n",
    "r2_test_ridge = r2_score(y_test, y_test_pred_ridge)\n",
    "\n",
    "r2_train_lasso = r2_score(y_train, y_train_pred_lasso)\n",
    "r2_test_lasso = r2_score(y_test, y_test_pred_lasso)\n",
    "\n",
    "# Calculer les erreurs (MAE et RMSE) pour l'entraînement et le test\n",
    "mae_train_elastic_net = mean_absolute_error(y_train, y_train_pred_elastic_net)\n",
    "rmse_train_elastic_net = mean_squared_error(y_train, y_train_pred_elastic_net, squared=False)\n",
    "mae_test_elastic_net = mean_absolute_error(y_test, y_test_pred_elastic_net)\n",
    "rmse_test_elastic_net = mean_squared_error(y_test, y_test_pred_elastic_net, squared=False)\n",
    "\n",
    "mae_train_ridge = mean_absolute_error(y_train, y_train_pred_ridge)\n",
    "rmse_train_ridge = mean_squared_error(y_train, y_train_pred_ridge, squared=False)\n",
    "mae_test_ridge = mean_absolute_error(y_test, y_test_pred_ridge)\n",
    "rmse_test_ridge = mean_squared_error(y_test, y_test_pred_ridge, squared=False)\n",
    "\n",
    "mae_train_lasso = mean_absolute_error(y_train, y_train_pred_lasso)\n",
    "rmse_train_lasso = mean_squared_error(y_train, y_train_pred_lasso, squared=False)\n",
    "mae_test_lasso = mean_absolute_error(y_test, y_test_pred_lasso)\n",
    "rmse_test_lasso = mean_squared_error(y_test, y_test_pred_lasso, squared=False)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"ElasticNet - R² pour l'entraînement:\", r2_train_elastic_net)\n",
    "print(\"ElasticNet - R² pour le test:\", r2_test_elastic_net)\n",
    "print(\"ElasticNet - Mean Absolute Error (MAE) pour l'entraînement:\", mae_train_elastic_net)\n",
    "print(\"ElasticNet - Mean Absolute Error (MAE) pour le test:\", mae_test_elastic_net)\n",
    "print(\"ElasticNet - Root Mean Squared Error (RMSE) pour l'entraînement:\", rmse_train_elastic_net)\n",
    "print(\"ElasticNet - Root Mean Squared Error (RMSE) pour le test:\", rmse_test_elastic_net)\n",
    "\n",
    "print(\"\\nRidge - R² pour l'entraînement:\", r2_train_ridge)\n",
    "print(\"Ridge - R² pour le test:\", r2_test_ridge)\n",
    "print(\"Ridge - Mean Absolute Error (MAE) pour l'entraînement:\", mae_train_ridge)\n",
    "print(\"Ridge - Mean Absolute Error (MAE) pour le test:\", mae_test_ridge)\n",
    "print(\"Ridge - Root Mean Squared Error (RMSE) pour l'entraînement:\", rmse_train_ridge)\n",
    "print(\"Ridge - Root Mean Squared Error (RMSE) pour le test:\", rmse_test_ridge)\n",
    "\n",
    "print(\"\\nLasso - R² pour l'entraînement:\", r2_train_lasso)\n",
    "print(\"Lasso - R² pour le test:\", r2_test_lasso)\n",
    "print(\"Lasso - Mean Absolute Error (MAE) pour l'entraînement:\", mae_train_lasso)\n",
    "print(\"Lasso - Mean Absolute Error (MAE) pour le test:\", mae_test_lasso)\n",
    "print(\"Lasso - Root Mean Squared Error (RMSE) pour l'entraînement:\", rmse_train_lasso)\n",
    "print(\"Lasso - Root Mean Squared Error (RMSE) pour le test:\", rmse_test_lasso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b792ea27-8bba-4701-81d5-97505db7efef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d66e61-7da2-4da6-9833-e8611fb185e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e406eb3-1393-4a0c-aa37-8e1e71e3c1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f44be66-568c-4cbf-b147-25809f5e1d5c",
   "metadata": {},
   "source": [
    "### <font color='blue'> Analyse data voitures hybrides : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5316c2-1d39-4dc0-933f-4374001b496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Tracer un histogramme\n",
    "sns.histplot(df_hybride['Emission_co2_(g/km)'], kde=True, bins=50, edgecolor='black', color='blue', line_kws={'color': 'red', 'linewidth': 2})\n",
    "\n",
    "\n",
    "# Calculer la moyenne et la médiane\n",
    "mean_value = df_hybride['Emission_co2_(g/km)'].mean()\n",
    "median_value = df_hybride['Emission_co2_(g/km)'].median()\n",
    "\n",
    "# Tracer des lignes verticales pour représenter la moyenne et la médiane\n",
    "plt.axvline(mean_value, color='red', linewidth=1, label='Moyenne de distribution')\n",
    "plt.axvline(median_value, color='red', linestyle='dashed', linewidth=1, label='Médiane de distribution')\n",
    "\n",
    "# Ajouter une légende\n",
    "plt.legend()\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130e9d43-31b0-4226-9008-cd93537b5cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_hybride['Emission_co2_(g/km)']\n",
    "X = df_hybride.drop('Emission_co2_(g/km)', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b67e1a-2a72-4b5a-b34c-f622540bc164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardiser les données\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e2874e-b816-4567-8ea8-3e4a0bcd8629",
   "metadata": {},
   "source": [
    "### <font color='blue'> sans validation croisée : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4292b6-041b-4bfe-a794-0be03cf127ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "# Création et entraînement du modèle de régression linéaire\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédiction des valeurs cibles pour les ensembles d'entraînement et de test\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calcul des métriques pour l'entraînement\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "# Calcul des métriques pour le test\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print(\"Régression Linéaire sans validation croisée\")\n",
    "print(f\"R² pour l'entraînement : {r2_train}\")\n",
    "print(f\"R² pour le test : {r2_test}\")\n",
    "print(f\"MAE pour l'entraînement : {mae_train}\")\n",
    "print(f\"MAE pour le test : {mae_test}\")\n",
    "print(f\"RMSE pour l'entraînement : {rmse_train}\")\n",
    "print(f\"RMSE pour le test : {rmse_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0715ad0-b579-4a58-908d-b8651e3c6ff9",
   "metadata": {},
   "source": [
    "### <font color='blue'> Avec validation croisée : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daeb150-0d60-4f76-b470-13d5c4498f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "# Validation croisée\n",
    "cv_results = cross_validate(model, X_train_scaled, y_train, cv=10,\n",
    "                            scoring=('r2', 'neg_mean_absolute_error', 'neg_root_mean_squared_error'),\n",
    "                            return_train_score=True)\n",
    "\n",
    "# Moyennes des scores R², MAE et RMSE pour l'entraînement et le test\n",
    "mean_r2_train = np.mean(cv_results['train_r2'])\n",
    "mean_r2_test = np.mean(cv_results['test_r2'])\n",
    "mean_mae_train = -np.mean(cv_results['train_neg_mean_absolute_error'])\n",
    "mean_mae_test = -np.mean(cv_results['test_neg_mean_absolute_error'])\n",
    "mean_rmse_train = -np.mean(cv_results['train_neg_root_mean_squared_error'])\n",
    "mean_rmse_test = -np.mean(cv_results['test_neg_root_mean_squared_error'])\n",
    "\n",
    "print(\"Régression Linéaire avec validation croisée\")\n",
    "print(f\"R² moyen pour l'entraînement : {mean_r2_train}\")\n",
    "print(f\"R² moyen pour le test : {mean_r2_test}\")\n",
    "print(f\"MAE moyen pour l'entraînement : {mean_mae_train}\")\n",
    "print(f\"MAE moyen pour le test : {mean_mae_test}\")\n",
    "print(f\"RMSE moyen pour l'entraînement : {mean_rmse_train}\")\n",
    "print(f\"RMSE moyen pour le test : {mean_rmse_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ef330-7874-47c4-b7c5-45c93ceb1b38",
   "metadata": {},
   "source": [
    "### <font color='blue'> Analyse des résidus : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a50578-f282-4297-b2d5-46b4681c328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer les résidus\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "# Visualiser les résidus\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Distribution des résidus')\n",
    "plt.xlabel('Résidus')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.show()\n",
    "# Enregistrer l'image\n",
    "plt.savefig('distribution des lr thermiques.png', bbox_inches='tight')\n",
    "\n",
    "# Vérifier l'homoscédasticité\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test_pred, y=residuals)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.title('Résidus par rapport aux valeurs prédites')\n",
    "plt.xlabel('Valeurs prédites')\n",
    "plt.ylabel('Résidus')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91718fa5-aa8a-4c37-be94-0b24d4725545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684b964b-14ad-412c-9303-5299e749bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialiser les modèles\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "ridge = Ridge(alpha=0.1)\n",
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "# Entraîner les modèles\n",
    "elastic_net.fit(X_train_scaled, y_train)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédire les valeurs cibles pour les ensembles d'entraînement et de test\n",
    "y_train_pred_elastic_net = elastic_net.predict(X_train_scaled)\n",
    "y_test_pred_elastic_net = elastic_net.predict(X_test_scaled)\n",
    "\n",
    "y_train_pred_ridge = ridge.predict(X_train_scaled)\n",
    "y_test_pred_ridge = ridge.predict(X_test_scaled)\n",
    "\n",
    "y_train_pred_lasso = lasso.predict(X_train_scaled)\n",
    "y_test_pred_lasso = lasso.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# Calculer les scores R² pour l'entraînement et le test\n",
    "r2_train_elastic_net = r2_score(y_train, y_train_pred_elastic_net)\n",
    "r2_test_elastic_net = r2_score(y_test, y_test_pred_elastic_net)\n",
    "\n",
    "r2_train_ridge = r2_score(y_train, y_train_pred_ridge)\n",
    "r2_test_ridge = r2_score(y_test, y_test_pred_ridge)\n",
    "\n",
    "r2_train_lasso = r2_score(y_train, y_train_pred_lasso)\n",
    "r2_test_lasso = r2_score(y_test, y_test_pred_lasso)\n",
    "\n",
    "# Calculer les erreurs (MAE et RMSE) pour l'entraînement et le test\n",
    "mae_train_elastic_net = mean_absolute_error(y_train, y_train_pred_elastic_net)\n",
    "rmse_train_elastic_net = mean_squared_error(y_train, y_train_pred_elastic_net, squared=False)\n",
    "mae_test_elastic_net = mean_absolute_error(y_test, y_test_pred_elastic_net)\n",
    "rmse_test_elastic_net = mean_squared_error(y_test, y_test_pred_elastic_net, squared=False)\n",
    "\n",
    "mae_train_ridge = mean_absolute_error(y_train, y_train_pred_ridge)\n",
    "rmse_train_ridge = mean_squared_error(y_train, y_train_pred_ridge, squared=False)\n",
    "mae_test_ridge = mean_absolute_error(y_test, y_test_pred_ridge)\n",
    "rmse_test_ridge = mean_squared_error(y_test, y_test_pred_ridge, squared=False)\n",
    "\n",
    "mae_train_lasso = mean_absolute_error(y_train, y_train_pred_lasso)\n",
    "rmse_train_lasso = mean_squared_error(y_train, y_train_pred_lasso, squared=False)\n",
    "mae_test_lasso = mean_absolute_error(y_test, y_test_pred_lasso)\n",
    "rmse_test_lasso = mean_squared_error(y_test, y_test_pred_lasso, squared=False)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"ElasticNet - R² pour l'entraînement:\", r2_train_elastic_net)\n",
    "print(\"ElasticNet - R² pour le test:\", r2_test_elastic_net)\n",
    "print(\"ElasticNet - Mean Absolute Error (MAE) pour l'entraînement:\", mae_train_elastic_net)\n",
    "print(\"ElasticNet - Mean Absolute Error (MAE) pour le test:\", mae_test_elastic_net)\n",
    "print(\"ElasticNet - Root Mean Squared Error (RMSE) pour l'entraînement:\", rmse_train_elastic_net)\n",
    "print(\"ElasticNet - Root Mean Squared Error (RMSE) pour le test:\", rmse_test_elastic_net)\n",
    "\n",
    "print(\"\\nRidge - R² pour l'entraînement:\", r2_train_ridge)\n",
    "print(\"Ridge - R² pour le test:\", r2_test_ridge)\n",
    "print(\"Ridge - Mean Absolute Error (MAE) pour l'entraînement:\", mae_train_ridge)\n",
    "print(\"Ridge - Mean Absolute Error (MAE) pour le test:\", mae_test_ridge)\n",
    "print(\"Ridge - Root Mean Squared Error (RMSE) pour l'entraînement:\", rmse_train_ridge)\n",
    "print(\"Ridge - Root Mean Squared Error (RMSE) pour le test:\", rmse_test_ridge)\n",
    "\n",
    "print(\"\\nLasso - R² pour l'entraînement:\", r2_train_lasso)\n",
    "print(\"Lasso - R² pour le test:\", r2_test_lasso)\n",
    "print(\"Lasso - Mean Absolute Error (MAE) pour l'entraînement:\", mae_train_lasso)\n",
    "print(\"Lasso - Mean Absolute Error (MAE) pour le test:\", mae_test_lasso)\n",
    "print(\"Lasso - Root Mean Squared Error (RMSE) pour l'entraînement:\", rmse_train_lasso)\n",
    "print(\"Lasso - Root Mean Squared Error (RMSE) pour le test:\", rmse_test_lasso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5be4408-938c-4336-93ae-42c3121b20ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e547b09-f866-45af-895a-f06cc08d8b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "598d0103-f52e-4727-b842-6efd3e8eec6a",
   "metadata": {},
   "source": [
    "#### <font color='pink'> Regression linéaire : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a6f63b-1bf2-4fdd-bd92-7c9d93c0d2e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eacd63-3365-43ba-9d6d-64f7afed29bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création et entraînement du modèle de régression linéaire\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédiction des valeurs cibles pour les ensembles d'entraînement et de test\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calcul des métriques de performance\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f'R² pour l\\'entraînement: {r2_train}')\n",
    "print(f'R² pour le test: {r2_test}')\n",
    "print(f'Mean Absolute Error (MAE) pour le test: {mae_test}')\n",
    "print(f'Root Mean Squared Error (RMSE) pour le test: {rmse_test}')\n",
    "\n",
    "# Visualisation des résultats\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_test_pred, color='blue', edgecolor='k', alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
    "plt.title('Nuage de points y_test vs y_test_pred')\n",
    "plt.xlabel('Valeurs réelles de CO2Emissions')\n",
    "plt.ylabel('Valeurs prédites de CO2Emissions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e5b88e-181f-4157-af93-75c36b688968",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be7866-c149-4e8b-891b-99042e0983f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer les résidus\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "# Tracer un graphique des résidus par rapport aux valeurs prédites\n",
    "plt.scatter(y_test_pred, residuals)\n",
    "plt.xlabel('Valeurs prédites')\n",
    "plt.ylabel('Résidus')\n",
    "plt.title('Graphique des résidus')\n",
    "plt.axhline(y=0, color='red', linestyle='--')  # Ajouter une ligne à 0 pour la référence\n",
    "plt.show()\n",
    "\n",
    "# Histogramme des résidus\n",
    "plt.hist(residuals, bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Résidus')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.title('Histogramme des résidus')\n",
    "plt.show()\n",
    "\n",
    "# Graphique quantile-quantile (QQ plot) pour vérifier la normalité des résidus\n",
    "import scipy.stats as stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('Graphique quantile-quantile des résidus')\n",
    "plt.xlabel('Quantiles théoriques')\n",
    "plt.ylabel('Quantiles observés')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3dd6c9-c182-4277-aa78-181d9e5bf093",
   "metadata": {},
   "source": [
    "#### <font color='pink'> Random forest : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d62b81-2141-45f6-889b-2d9ba790c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédictions sur les données de test\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluation de la performance du modèle\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Affichage des métriques de performance\n",
    "print(\"Erreur quadratique moyenne (MSE) :\", mse)\n",
    "print(\"Erreur absolue moyenne (MAE) :\", mae)\n",
    "print(\"Coefficient de détermination (R²) :\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d357b7-bf3f-4e83-b138-bb50f41b03be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer les résidus\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Tracer un graphique des résidus par rapport aux valeurs prédites\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.xlabel('Valeurs prédites')\n",
    "plt.ylabel('Résidus')\n",
    "plt.title('Graphique des résidus')\n",
    "plt.axhline(y=0, color='red', linestyle='--')  # Ajouter une ligne à 0 pour la référence\n",
    "plt.show()\n",
    "\n",
    "# Histogramme des résidus\n",
    "plt.hist(residuals, bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Résidus')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.title('Histogramme des résidus')\n",
    "plt.show()\n",
    "\n",
    "# Graphique quantile-quantile (QQ plot) pour vérifier la normalité des résidus\n",
    "import scipy.stats as stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('Graphique quantile-quantile des résidus')\n",
    "plt.xlabel('Quantiles théoriques')\n",
    "plt.ylabel('Quantiles observés')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9693e12-3f3c-4277-a319-d0ed124f8e72",
   "metadata": {},
   "source": [
    "### <font color='blue'> Analyse data complet : </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c96be28-7076-46c6-8cc9-22ab9a89cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tracer un histogramme\n",
    "sns.histplot(df['Emission_co2_(g/km)'], kde=True, bins=50, edgecolor='black', color='blue', line_kws={'color': 'red', 'linewidth': 2})\n",
    "\n",
    "\n",
    "# Calculer la moyenne et la médiane\n",
    "mean_value = df['Emission_co2_(g/km)'].mean()\n",
    "median_value = df['Emission_co2_(g/km)'].median()\n",
    "# Tracer des lignes verticales pour représenter la moyenne et la médiane\n",
    "plt.axvline(mean_value, color='red', linewidth=1, label='Moyenne de la distribution')\n",
    "plt.axvline(median_value, color='red', linestyle='dashed', linewidth=1, label='Médiane de la distribution')\n",
    "\n",
    "# Ajouter une légende\n",
    "plt.legend()\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbec1b91-e99c-41e5-ba76-acaa2ce0df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Emission_co2_(g/km)']\n",
    "X = df.drop('Emission_co2_(g/km)', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654bf28-67ed-4981-99f7-1a47260e570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardiser les données\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a785d5-1936-4aa3-87de-9b1cc2e815cf",
   "metadata": {},
   "source": [
    "### <font color='blue'> Régression Linéaire : </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9601fd-5422-4337-bd55-4fccc7e16a85",
   "metadata": {},
   "source": [
    "La régression linéaire est fondée sur les hypothèses suivantes : centrage, homoscédasticité, indépendance et normalité des erreurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dbe932-9f81-447d-b6e3-b58c6c52d745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Création du modèle de régression linéaire\n",
    "model = LinearRegression()\n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "# Prédictions sur les données de test\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluation de la performance du modèle\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Affichage des métriques de performance\n",
    "print(\"Erreur quadratique moyenne (MSE) :\", mse)\n",
    "print(\"Erreur absolue moyenne (MAE) :\", mae)\n",
    "print(\"Coefficient de détermination (R²) :\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca1ae92-5add-418a-93be-6c0c3d6b532d",
   "metadata": {},
   "source": [
    "**Erreur quadratique moyenne (MSE)** Cela signifie que, en moyenne, les prédictions du modèle diffèrent des vraies valeurs d'environ 142.78 unités au carré.\n",
    "**Erreur absolue moyenne (MAE)** le MAE est d'environ 8.75. Cela signifie que, en moyenne, les prédictions de votre modèle diffèrent des vraies valeurs d'environ 8.75 unités.\n",
    "**Coefficient de détermination (R²)** Cela signifie que le modèle explique environ 88% de la variance des émissions de CO2, ce qui est une bonne performance.\n",
    "\n",
    "**En résumé, notre modèle de régression linéaire semble bien fonctionner, avec un R² élevé et des valeurs de MSE et MAE relativement basses, ce qui indique qu'il est capable de faire des prédictions précises sur les émissions de CO2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1362b1c3-d691-4f37-a852-5e02b3f49399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Prédictions sur les données d'entraînement\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "\n",
    "# Prédictions sur les données de test\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calcul des métriques sur les données d'entraînement\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calcul des métriques sur les données de test\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Affichage des métriques pour les données d'entraînement\n",
    "print(\"Métriques pour les données d'entraînement :\")\n",
    "print(\"MSE :\", mse_train)\n",
    "print(\"MAE :\", mae_train)\n",
    "print(\"R²  :\", r2_train)\n",
    "print()\n",
    "\n",
    "# Affichage des métriques pour les données de test\n",
    "print(\"Métriques pour les données de test :\")\n",
    "print(\"MSE :\", mse_test)\n",
    "print(\"MAE :\", mae_test)\n",
    "print(\"R²  :\", r2_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6534f38f-fea2-4801-b7aa-6d3e21676823",
   "metadata": {},
   "source": [
    "**Interpretation :** Ces métriques indiquent que le modèle a une performance similaire sur les ensembles d'entraînement et de test, ce qui suggère qu'il généralise bien aux données non vues. \n",
    "Le R² proche de 0.88 indique que le modèle explique environ 88% de la variance des émissions de CO2, ce qui est une performance solide pour une régression linéaire. \n",
    "Les valeurs MSE et MAE relativement faibles indiquent également que les prédictions du modèle sont précises.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cca59c-28ec-4bbd-a993-3852d2fae5f5",
   "metadata": {},
   "source": [
    "#### <font color='pink'> Analyse des résidus : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6478392-575c-4713-aa76-1c4e22363fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer les résidus\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "# Tracer un graphique des résidus par rapport aux valeurs prédites\n",
    "plt.scatter(y_test_pred, residuals)\n",
    "plt.xlabel('Valeurs prédites')\n",
    "plt.ylabel('Résidus')\n",
    "plt.title('Graphique des résidus')\n",
    "plt.axhline(y=0, color='red', linestyle='--')  # Ajouter une ligne à 0 pour la référence\n",
    "plt.show()\n",
    "\n",
    "# Histogramme des résidus\n",
    "plt.hist(residuals, bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Résidus')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.title('Histogramme des résidus')\n",
    "plt.show()\n",
    "\n",
    "# Graphique quantile-quantile (QQ plot) pour vérifier la normalité des résidus\n",
    "import scipy.stats as stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('Graphique quantile-quantile des résidus')\n",
    "plt.xlabel('Quantiles théoriques')\n",
    "plt.ylabel('Quantiles observés')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5acb08-9054-4818-9d33-e4d2cfa04ea2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a38df0-42d9-4b5d-853e-41aea9f0df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les coefficients de régression\n",
    "coefficients = pd.DataFrame({'Variable': X.columns, 'Coefficient': model.coef_})\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c8b5e1-3c97-4c3a-89c7-555a04faa370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Créer un DataFrame des coefficients de régression\n",
    "coefficients = pd.DataFrame({'Variable': X.columns, 'Coefficient': model.coef_})\n",
    "\n",
    "# Trier les coefficients par valeur absolue\n",
    "coefficients['Abs_Coefficient'] = abs(coefficients['Coefficient'])\n",
    "coefficients = coefficients.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "# Afficher les coefficients\n",
    "print(coefficients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb448ca6-3d2e-441b-bddb-5b49100b1d4c",
   "metadata": {},
   "source": [
    "s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1790044c-4234-417c-b145-7726f8c2d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Créer un DataFrame des coefficients de régression\n",
    "coefficients = pd.DataFrame({'Variable': X.columns, 'Coefficient': model.coef_})\n",
    "\n",
    "# Trier les coefficients par valeur absolue\n",
    "coefficients['Abs_Coefficient'] = abs(coefficients['Coefficient'])\n",
    "coefficients = coefficients.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "# Créer le graphique\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(coefficients['Variable'], coefficients['Coefficient'], color='skyblue')\n",
    "plt.xlabel('Coefficient de régression')\n",
    "plt.ylabel('Variables')\n",
    "plt.title('Coefficients de régression')\n",
    "plt.grid(axis='x')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b210c1-227e-4d17-bb97-a044dac72320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner les nouvelles variables explicatives\n",
    "X_new = df[['Consommation_électrique', 'feature1', 'Puissance_moteur', 'Fuel_petrol/electric', 'Autonomie_électrique']]\n",
    "\n",
    "# Fractionner les données en ensembles d'entraînement et de test\n",
    "X_train_new, X_test_new, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardiser les données\n",
    "scaler_new = StandardScaler()\n",
    "X_train_scaled_new = scaler_new.fit_transform(X_train_new)\n",
    "X_test_scaled_new = scaler_new.transform(X_test_new)\n",
    "\n",
    "# Créer et entraîner le modèle de régression linéaire\n",
    "model_new = LinearRegression()\n",
    "model_new.fit(X_train_scaled_new, y_train)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "y_pred_new = model_new.predict(X_test_scaled_new)\n",
    "\n",
    "# Calculer les métriques de performance\n",
    "mse_new = mean_squared_error(y_test, y_pred_new)\n",
    "mae_new = mean_absolute_error(y_test, y_pred_new)\n",
    "r2_new = r2_score(y_test, y_pred_new)\n",
    "\n",
    "# Afficher les métriques de performance\n",
    "print(\"Métriques pour les données de test avec les nouvelles variables explicatives :\")\n",
    "print(\"MSE :\", mse_new)\n",
    "print(\"MAE :\", mae_new)\n",
    "print(\"R²  :\", r2_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d70fef-530f-4a99-9f43-8f4208dddf68",
   "metadata": {},
   "source": [
    "**MSE (Mean Squared Error) :**\n",
    "Nouveau modèle : 167.72\n",
    "Premier modèle : 142.\n",
    "**MAE (Mean Absolute Error) :**\n",
    "Nouveau modèle : 9.69\n",
    "Premier modèle : 8.\n",
    "**R² (Coefficient de détermination) :**\n",
    "Nouveau modèle : 0.858\n",
    "Premier modèle : 0.8\n",
    "\n",
    "**En résumé, le premier modèle avec les anciennes variables explicatives semble donner de meilleures performances, avec des valeurs de MSE et de MAE inférieures ainsi qu'un R² plus élevé par rapport au nouveau modèle avec les nouvelles variables explicatives. Cela suggère que les nouvelles variables ne contribuent pas autant à la prédiction de la variable cible par rapport aux anciennes variables. Il pourrait être utile de réexaminer les variables choisies et leur impact sur le modèle.**797578"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b5538a-3353-4d90-b248-fdd3b42472ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Définir le modèle de régression linéaire\n",
    "model = LinearRegression()\n",
    "\n",
    "# Définir les hyperparamètres à tester\n",
    "param_grid = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'positive': [True, False]\n",
    "}\n",
    "\n",
    "# Créer un objet GridSearchCV\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Exécuter la recherche sur grille sur les données d'entraînement\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramètres\n",
    "print(\"Meilleurs paramètres :\", grid_search.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2698c9-cd69-4a78-b965-8e4290834961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Créer un nouveau modèle de régression linéaire avec les meilleurs paramètres\n",
    "best_model = LinearRegression(fit_intercept=True, positive=False)\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculer les métriques de performance\n",
    "mse_best = mean_squared_error(y_test, y_pred_best)\n",
    "mae_best = mean_absolute_error(y_test, y_pred_best)\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "# Afficher les métriques de performance\n",
    "print(\"Métriques de performance avec les meilleurs paramètres :\")\n",
    "print(\"MSE :\", mse_best)\n",
    "print(\"MAE :\", mae_best)\n",
    "print(\"R²  :\", r2_best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db26e22-c579-4578-875a-545aa7d30760",
   "metadata": {},
   "source": [
    "### <font color='blue'> Random forest : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512f86ff-7c5e-43ae-804c-b7d2a8837661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divisez les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Instanciez le RandomForestRegressor avec les hyperparamètres désirés\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Effectuez une validation croisée pour évaluer les performances du modèle\n",
    "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_mse_scores = -cv_scores  # Convertissez les scores de perte négatifs en valeurs positives\n",
    "\n",
    "# Entraînez le modèle sur les données d'entraînement\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Faites des prédictions sur les données de test\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculez les métriques de performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Affichez les métriques de performance\n",
    "print(\"Scores de validation croisée (MSE) :\", cv_mse_scores)\n",
    "print(\"Moyenne des scores :\", cv_mse_scores.mean())\n",
    "print(\"MSE :\", mse)\n",
    "print(\"MAE :\", mae)\n",
    "print(\"R²  :\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0324c02-f88f-47b1-a152-4ddc7fcfda1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c623744-756c-4d8c-9e1f-e75095fc99f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "\n",
    "# Créer le modèle de réseau de neurones\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(10,), activation='relu'),  # Couche cachée avec 64 neurones et fonction d'activation ReLU\n",
    "    Dense(32, activation='relu'),  # Une autre couche cachée avec 32 neurones et fonction d'activation ReLU\n",
    "    Dense(1, activation='sigmoid')  # Couche de sortie avec 1 neurone et fonction d'activation sigmoïde pour les problèmes de classification binaire\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a0809a-c977-44e8-8287-59a30bf451bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Définir le modèle CNN\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Ajout de dropout pour prévenir le surapprentissage\n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))\n",
    "\n",
    "# Évaluer le modèle\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5f371-681d-4c1e-8945-84cf58498807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9e36e6-4295-4aab-82f8-15c72adc7316",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, img_channels)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Dropout pour prévenir le surapprentissage\n",
    "    layers.Dense(num_classes)  # Assurez-vous de remplacer num_classes par le nombre de classes dans vos données\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
